{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claims Matching Rules\n",
    "1. Carrier excel file(s) must be in .xlsx format (if .xls, you must convert to .xlsx)\n",
    "2. This Python file must be in the same folder as your data\n",
    "3. You can create a copy of this file and paste into your client folder where carrier data is located\n",
    "4. If this is your first time using this code, remove # from the below installer, run code\n",
    "5. If you have multiple sheets in 1 workbook, enter them in as if they were seperate requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Time User - Install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To install the below, remove the hashtag from all lines of code and hit run\n",
    "# If you are NOT a first time user, skip this code and proceed to Step 1\n",
    "\n",
    "# !pip install xlsxwriter\n",
    "# !pip install xlutils\n",
    "# !pip install xlrd\n",
    "# !pip install xlwt\n",
    "# !pip install openpyxl\n",
    "# !pip install easygui\n",
    "# !pip install pillow\n",
    "# !pip install formlayout\n",
    "# !pip install PySide2\n",
    "# !pip install wxpython\n",
    "# !pip install dash\n",
    "# !pip install pysimplegui\n",
    "# !pip install pyxlsb\n",
    "# !pip3 install pyxlsb\n",
    "#!pip install --upgrade pip\n",
    "#!pip install joblib\n",
    "#!pip install sklearn\n",
    "# !pip install PyInstaller\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "***************************************\n",
      "               WELCOME                  \n",
      "***************************************\n",
      " \n",
      "---------------------------------------\n",
      "Medical/Rx Cliams Matching Tool (CMT)\n",
      "---------------------------------------\n",
      " \n",
      " \n",
      "             Instructions            \n",
      "=======================================\n",
      "     1. Review ALL files & identify which column(s) you will be matching on\n",
      "     2. CLOSE ALL files prior to start\n",
      "     3. DO NOT use original carrier files with code, make a copy\n",
      "     4. Create a working folder which includes your working files \n",
      "     5. Working folder should contain ONLY files you need matched\n",
      "\n",
      "             Matching Options        \n",
      "=======================================\n",
      "     1. Single Match\n",
      "        - You have 1 identifier i.e. SSN, Member ID, Claimant name in same format\n",
      "     2. Name Match & Name Match w/ DOB\n",
      "        - You have varying name formats\n",
      "        - You want to match on name + DOB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "print('***************************************')\n",
    "print(\"               WELCOME                  \")\n",
    "print('***************************************')\n",
    "print(' ')\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Medical/Rx Cliams Matching Tool (CMT)\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(\"             Instructions            \")\n",
    "print('=======================================')\n",
    "print(\"     1. Review ALL files & identify which column(s) you will be matching on\")\n",
    "print(\"     2. CLOSE ALL files prior to start\")\n",
    "print(\"     3. DO NOT use original carrier files with code, make a copy\")\n",
    "print(\"     4. Create a working folder which includes your working files \")\n",
    "print(\"     5. Working folder should contain ONLY files you need matched\")\n",
    "print('')\n",
    "print(\"             Matching Options        \")\n",
    "print('=======================================')\n",
    "print(\"     1. Single Match\")\n",
    "print(\"        - You have 1 identifier i.e. SSN, Member ID, Claimant name in same format\")\n",
    "print(\"     2. Name Match & Name Match w/ DOB\")\n",
    "print(\"        - You have varying name formats\")\n",
    "print(\"        - You want to match on name + DOB\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from os.path import expanduser as ospath\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from datetime import date\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill, Border, Side, Alignment, Protection, Font\n",
    "import joblib\n",
    "from xlrd import open_workbook\n",
    "import re\n",
    "import xlrd\n",
    "from sklearn import model_selection, preprocessing\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "from sklearn import model_selection, preprocessing, feature_extraction\n",
    "import sklearn.utils._cython_blas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colnum_string(n): \n",
    "    string=''\n",
    "    while n>0: \n",
    "        n, remainder=divmod(n-1, 26)\n",
    "        string=chr(65+remainder)+string\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOB - pull in all file in folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please copy/paste the directory path: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\n",
      "Please close all files in folder. Ready to move on? Yes=1, No=2 1\n",
      "Folder analysis start...\n",
      "\n",
      "Running analysis for .xls files in folder .xls files must be converted to .xlsx \n",
      "---\n",
      "Running analysis for .xlsb files in folder .xlsb files must be converted to .xlsb\n",
      "---\n",
      "Running analysis for .xlsx files folder this could take a few mintues, please wait\n",
      "---\n",
      "+----------------------------------------------------+\n",
      "1: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Cherokee Nation Businesses - RXT1210DM - Claim Detail Report - YTD 08-2019.xlsx :: Sheet: Large Claims\n",
      "+----------------------------------------------------+\n",
      "2: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Cherokee Nation Businesses - RXT1210DM - Claim Detail Report - YTD 08-2019.xlsx :: Sheet: LC over 25k\n",
      "+----------------------------------------------------+\n",
      "3: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Cherokee Nation Businesses - RXT1210DM - Claim Detail Report - YTD 08-2019.xlsx :: Sheet: Monthly Claims USE FOR EMR\n",
      "+----------------------------------------------------+\n",
      "4: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Cherokee Nation Businesses - RXT1210DM - Claim Detail Report - YTD 08-2019.xlsx :: Sheet: Claim Detail Report Page_1\n",
      "+----------------------------------------------------+\n",
      "5: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Cherokee Nation Businesses - RXT1210DM - Claim Detail Report - YTD 08-2019.xlsx :: Sheet: Report Conditions Page_2\n",
      "+----------------------------------------------------+\n",
      "6: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05.2016 thru 4.30.17.xlsx :: Sheet: CLAIM DETAIL\n",
      "+----------------------------------------------------+\n",
      "7: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05.2016 thru 4.30.17.xlsx :: Sheet: DATA_CNT\n",
      "+----------------------------------------------------+\n",
      "8: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05.2016 thru 4.30.17.xlsx :: Sheet: Anthem - Layout and Definitions\n",
      "+----------------------------------------------------+\n",
      "9: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05_17 thru 12.31.17.xlsx :: Sheet: CLAIM DETAIL\n",
      "+----------------------------------------------------+\n",
      "10: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05_17 thru 12.31.17.xlsx :: Sheet: DATA_CNT\n",
      "+----------------------------------------------------+\n",
      "11: File: C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05_17 thru 12.31.17.xlsx :: Sheet: Anthem - Layout and Definitions\n",
      "\n",
      "---\n",
      "Folder analysis complete...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "file_path=input('Please copy/paste the directory path: ')\n",
    "os.chdir = file_path\n",
    "\n",
    "files_closed = 2\n",
    "while not files_closed == 1:\n",
    "    files_closed = int(input(\"Please close all files in folder. Ready to move on? Yes=1, No=2 \"))\n",
    "\n",
    "#-----------------------GLOB XLS--------------------------\n",
    "# ##check all files with .xls in folder and return file name\n",
    "print('Folder analysis start...')\n",
    "print (\"\")\n",
    "print('Running analysis for .xls files in folder .xls files must be converted to .xlsx ')\n",
    "print (\"---\")\n",
    "\n",
    "\n",
    "\n",
    "files_xls = glob.glob(f'{file_path}\\*.xls')\n",
    "for folderfiles in files_xls:\n",
    "    print(f'Filename: {folderfiles}') \n",
    "    print (\"\")\n",
    "    print (\"---\")\n",
    "\n",
    "#-----------------------GLOB XLSB--------------------------\n",
    "\n",
    "#check all files with .xlsb in folder and return file name\n",
    "print('Running analysis for .xlsb files in folder .xlsb files must be converted to .xlsb')\n",
    "print (\"---\")\n",
    "files_xlsb = glob.glob(f'{file_path}\\*.xlsb')\n",
    "for folderfiles in files_xlsb:\n",
    "    print(f'Filename: {folderfiles}') \n",
    "    print (\"\")\n",
    "    print (\"---\")\n",
    "\n",
    "\n",
    "\n",
    "print('Running analysis for .xlsx files folder this could take a few mintues, please wait')\n",
    "print (\"---\")\n",
    "\n",
    "#-----------------------GLOB XLSX--------------------------\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "count=0\n",
    "file_selection={}\n",
    "files_xlsx = glob.glob(f'{file_path}\\*.xlsx')\n",
    "files_xlsx=[each_file for each_file in files_xlsx if not each_file[0:2] == '~$']\n",
    "for each_file in files_xlsx:\n",
    "    with open_workbook(each_file, on_demand=True) as book:\n",
    "        sheets=book.sheet_names()\n",
    "        #GO INTO EACH SHEET\n",
    "        for each_sheet in sheets: \n",
    "            new_file={}\n",
    "            count+=1\n",
    "            print(\"+----------------------------------------------------+\")\n",
    "            print(f'{count}: File: {each_file} :: Sheet: {each_sheet}')\n",
    "            new_file['file']=each_file\n",
    "            new_file['sheet']=each_sheet\n",
    "            file_selection[count]=new_file\n",
    "\n",
    "\n",
    "print (\"\")\n",
    "print (\"---\")\n",
    "print('Folder analysis complete...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\a0766635\\\\Desktop\\\\Python\\\\Cherokee\\\\Cherokee Nation Businesses - RXT1210DM - Claim Detail Report - YTD 08-2019.xlsx',\n",
       " 'C:\\\\Users\\\\a0766635\\\\Desktop\\\\Python\\\\Cherokee\\\\~$NonFuzzy.xlsx']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many sheets do we match on, and which sheets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input # of sheets to merge: i.e. 3 3\n",
      "Input # file/sheet index: 4\n",
      "Input # file/sheet index: 6\n",
      "Input # file/sheet index: 9\n",
      "\n",
      "Ready to move on? Yes=1, No=2: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## creating an empty list for inputs needed to identify key elements for the file\n",
    "confirm = 2\n",
    "while not confirm ==1:\n",
    "    \n",
    "    filename = []\n",
    "    sheetname = []\n",
    "    dfname = []\n",
    "    ## Clear any exisiting list items for fresh start\n",
    "    filename.clear()\n",
    "    sheetname.clear()\n",
    "    dfname.clear()\n",
    "\n",
    "\n",
    "    n = int(input('Input # of sheets to merge: i.e. 3 ' ))\n",
    "\n",
    "\n",
    "    ##iterating\n",
    "    for i in range(0, n): \n",
    "        selection=int(input('Input # file/sheet index: '))\n",
    "        ele1 = file_selection[selection]['file']\n",
    "        ele2 = file_selection[selection]['sheet']\n",
    "        ele3 = f'df{i}'\n",
    "        filename.append(ele1) ## adding the element \n",
    "        sheetname.append(ele2) ## adding the element\n",
    "        dfname.append(ele3)\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "#     print(f'You have selected the following files {filename}')\n",
    "#     print(f'You have selected the following sheet {sheetname}')\n",
    "    confirm = int(input(\"Ready to move on? Yes=1, No=2: \"))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask for row # where header should start (add machine learning here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "----IDENTIFYING HEADER(auto)----\n",
      "For C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Cherokee Nation Businesses - RXT1210DM - Claim Detail Report - YTD 08-2019.xlsx :: Claim Detail Report Page_1:\n",
      "  System identified header on row 15\n",
      " \n",
      "['Carrier ID', 'Carrier Name', 'Account ID', 'Account Name', 'Group ID', 'Group Name', 'Plan Code', 'Member ID', 'Member Last Name', 'Member First Name', 'Last, First', 'Member Middle Initial', 'Member Gender', 'Member Date of Birth', 'Member Address 1', 'Member Address 2', 'Member City', 'Member State', 'Member Zip', 'Member Phone', 'Date Filled', 'Incurred Month', 'Date Submitted', 'Paid Month', 'RxCLAIM Number', 'RxCLAIM Sequence Number', 'RxCLAIM Status', 'Rx Number', 'Refill Number', 'Claim Origin Code', 'Prescriber Submitted ID', 'Prescriber DEA ID', 'Prescriber NPI', 'Prescriber Last Name', 'Prescriber First Name', 'Prescriber Middle Initial', 'Prescriber Degree', 'Prescriber Address 1', 'Prescriber Address 2', 'Prescriber City', 'Prescriber State', 'Prescriber Zip', 'Prescriber Phone', 'Prescriber Fax', 'Pharmacy Submitted ID', 'Pharmacy NCPDP ID', 'Pharmacy NPI', 'Pharmacy Name', 'Pharmacy Address 1', 'Pharmacy Address 2', 'Pharmacy City', 'Pharmacy State', 'Pharmacy Zip', 'Pharmacy Phone', 'Pharmacy Fax', 'Drug GPI', 'Drug NDC', 'Drug Group Description (GPI 02)', 'Drug Name', 'Drug Name and Strength', 'Drug DEA Code', 'Drug Maintenance Code', 'Generic Indicator Override', 'DAW Code', 'Specialty / Non-Specialty Code', 'Mail / Retail Code', 'Brand / Generic Code', 'Total Quantity', 'Total Days Supply', 'Avg Quantity / Day', 'Total Rxs', 'Total Drug Cost', 'Total Ingredient Cost', 'Total Dispensing Fee', 'Total Sales Tax', 'Total Incentive Fee', 'Total Plan Paid', 'Total Member Paid', 'Total Copay', 'Total DAW Penalty', 'Total Deductible', 'Unnamed: 81']\n",
      "Correct header row? 1=Yes, 2=No 1\n",
      "Processing...\n",
      " \n",
      "----IDENTIFYING HEADER(auto)----\n",
      "For C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05.2016 thru 4.30.17.xlsx :: CLAIM DETAIL:\n",
      "  System identified header on row 1\n",
      " \n",
      "['Date of Service', 'Invoice Date', 'Drug Name', 'NDC', 'Drug Type', 'Formulary Ind', 'Specialty Drug', 'Maintenance Drug', 'Days Supply', 'Fill QTY', 'Member SSN', 'Dep SSN', 'Person Nbr', 'Relshp Cde', 'First Name', 'Last Name', 'Effective Date', 'End Date', 'Birth Dte', 'Gender', 'Net Plan Cost']\n",
      "Correct header row? 1=Yes, 2=No 1\n",
      "Processing...\n",
      " \n",
      "----IDENTIFYING HEADER(auto)----\n",
      "For C:\\Users\\a0766635\\Desktop\\Python\\Cherokee\\data\\Rx - Historical Claims 05_17 thru 12.31.17.xlsx :: CLAIM DETAIL:\n",
      "  System identified header on row 1\n",
      " \n",
      "['Date of Service', 'Invoice Date', 'Drug Name', 'NDC', 'Drug Type', 'Formulary Ind', 'Specialty Drug', 'Maintenance Drug', 'Days Supply', 'Fill QTY', 'Member SSN', 'Dep SSN', 'Person Nbr', 'Relshp Cde', 'First Name', 'Last Name', 'Effective Date', 'End Date', 'Birth Dte', 'Gender', 'Net Plan Cost']\n",
      "Correct header row? 1=Yes, 2=No 1\n",
      "Processing...\n"
     ]
    }
   ],
   "source": [
    "#pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "##Machine learning\n",
    "test_texts=[]\n",
    "row_nums=[]\n",
    "row_nums.clear()\n",
    "headerrow = []\n",
    "headerrow.clear\n",
    "exceldict = {}\n",
    "header_row_num_ML=[]\n",
    "exceldict.clear()\n",
    "df={}\n",
    "\n",
    "Correct_header=2\n",
    "confirm = 2\n",
    "while not confirm ==1:\n",
    "    for i in range(len(filename)):\n",
    "        with open_workbook(filename[i], on_demand=True) as book:\n",
    "            sheet=book.sheet_by_name(sheetname[i])\n",
    "            try:\n",
    "                for each_row in range(min(sheet.nrows, 20)):\n",
    "                    text=sheet.row_values(each_row)[0:]\n",
    "                    text_stitch=' '.join(str(cell) for cell in text if re.search('[a-zA-Z]', str(cell)))\n",
    "                    if not text_stitch=='': \n",
    "                        row_nums.append(each_row)\n",
    "                        test_texts.append(text_stitch)\n",
    "                #print(test_texts)\n",
    "                df[dfname[i]]=pd.DataFrame()\n",
    "                df[dfname[i]]['text']=test_texts\n",
    "                df[dfname[i]]['row_num']=row_nums  \n",
    "                count_vectorizer=joblib.load('Count_vectorizer.sav')\n",
    "                model=joblib.load('LR_model.sav')\n",
    "                test_vector=count_vectorizer.transform(df[dfname[i]]['text'])\n",
    "                df[dfname[i]]['label']=model.predict(test_vector)\n",
    "                header_row_num=df[dfname[i]][df[dfname[i]]['label']==1]['row_num'].values[0]\n",
    "                print(\" \")\n",
    "                print(\"----IDENTIFYING HEADER(auto)----\")\n",
    "                print(f\"For {filename[i]} :: {sheetname[i]}:\")\n",
    "                print(f'  System identified header on row {header_row_num+1}')\n",
    "                print(\" \")\n",
    "                df1 = pd.read_excel(f'{filename[i]}', (sheetname[i]), header=header_row_num, dtype={'column': object})\n",
    "                #print(f'For {filename[i]}, {sheetname[i]} system identified header at excel row {header_row_num_ML+1}')\n",
    "                print (list(df1.head(0)))\n",
    "                Correct_header=int(input(\"Correct header row? 1=Yes, 2=No \"))\n",
    "                print(\"Processing...\")\n",
    "\n",
    "                if Correct_header == 1:\n",
    "                    headerrow.append(header_row_num)\n",
    "                    exceldict[dfname[i]] = pd.read_excel(f'{filename[i]}', (sheetname[i]), header=headerrow[i], dtype={'column': object})\n",
    "                    test_texts.clear()\n",
    "                    row_nums.clear()\n",
    "                else:\n",
    "                    print(\"----IDENTIFYING HEADER(else)----\")\n",
    "                    print(f'For {filename[i]} :: {sheetname[i]}:' )\n",
    "                    print(\" \")\n",
    "                    print(pd.read_excel(f'{filename[i]}', (sheetname[i]), header=None).iloc[:15, :2])\n",
    "                    #exceldict[dfname[i]] = pd.read_excel(f'{filename[i]}', (sheetname[i]), header=None, dtype={'column': object})\n",
    "                    #print(exceldict[dfname[i]].iloc[:18, :2])\n",
    "                    header_num = int(input(\"Review in left column, what row # does your header start in? \"))\n",
    "                    print(\"Processing...\")\n",
    "                    headerrow.append(header_num)\n",
    "                    exceldict[dfname[i]] = pd.read_excel(f'{filename[i]}', (sheetname[i]), header=headerrow[i], dtype={'column': object}, inplace=True)\n",
    "                    test_texts.clear()\n",
    "                    row_nums.clear()\n",
    "            except:\n",
    "                print(\" \")\n",
    "                print(\"----IMPORTANT: PLEASE SEND COPY OF THIS FILE TO SANDY.LUCEV@AON.COM----\")\n",
    "                print(\"----IDENTIFYING HEADER(except)----\")\n",
    "                print(f'For {filename[i]} :: {sheetname[i]}:' )\n",
    "                print(\" \")\n",
    "                print(pd.read_excel(f'{filename[i]}', (sheetname[i]), header=None).iloc[:15, :2])\n",
    "                #exceldict[dfname[i]] = pd.read_excel(f'{filename[i]}', (sheetname[i]), header=None, dtype={'column': object})\n",
    "                #print(exceldict[dfname[i]].iloc[:18, :2])\n",
    "                header_num = int(input(\"Review in left column, what row # does your header start in? \"))\n",
    "                headerrow.append(header_num)\n",
    "                exceldict[dfname[i]] = pd.read_excel(f'{filename[i]}', (sheetname[i]), header=headerrow[i], dtype={'column': object}, inplace=True)\n",
    "                test_texts.clear()\n",
    "                row_nums.clear()\n",
    "    confirm = int(input(\"Ready to move on? Yes=1, No=2: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick matching id from the selected headers.\n",
    "##what if the header i want to match on has a different name i.e. Member ID / Mem ID? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: identifying match criteria\n",
      "Processing: This may take a few minutes... \n",
      " \n",
      " \n",
      "----IDENTIFYING MATCH COLUMN----\n",
      "  Review header columns for: C:\\Users\\a0766635\\Desktop\\Python\\Cigna Med Rx 1\\data\\CIGNA - Med & Rx2017onDesk.xlsx, 17-18-1\n",
      " \n",
      "  0: BRANCH\n",
      "  1: FAT\n",
      "  2: RAT\n",
      "  3: MEMBER ID\n",
      "  4: EMPLOYEE ID\n",
      "  5: SUBSCRIBER NAME\n",
      "  6: REL\n",
      "  7: GENDER\n",
      "  8: AGE BAND\n",
      "  9: ICD CODE\n",
      "  10: ICD DESCRIPTION\n",
      "  11: ICD VERSION\n",
      "  12: DRUG CLAIMS\n",
      "  13: PAID CLAIMS\n",
      "  14: CLAIMANT TOTAL\n",
      "  15: Unnamed: 15\n",
      "  16: Unnamed: 16\n",
      "  17: Unnamed: 17\n",
      "  18: Unnamed: 18\n",
      "  19: Unnamed: 19\n",
      "  20: Unnamed: 20\n",
      "  21: Unnamed: 21\n",
      "  22: Unnamed: 22\n",
      "  23: Unnamed: 23\n",
      "  24: Claimant ID\n",
      "  25: Unique Claimant ID\n",
      "  26: Unique Claimant ID.1\n",
      "  27: Unique Claimant ID.2\n",
      "  28: Unique Claimant ID.3\n",
      "  29: Unique Claimant ID.4\n",
      "  30: Unique Claimant ID.5\n",
      " \n",
      "\n",
      "Select Index # to match: 4\n",
      "--------------------------\n",
      " \n",
      "----IDENTIFYING MATCH COLUMN----\n",
      "  Review header columns for: C:\\Users\\a0766635\\Desktop\\Python\\Cigna Med Rx 1\\data\\CIGNA - Med & Rx2018.xlsx, 18-19-1\n",
      " \n",
      "  0: BRANCH\n",
      "  1: FAT\n",
      "  2: RAT\n",
      "  3: MEMBER ID\n",
      "  4: EMPLOYEE ID\n",
      "  5: SUBSCRIBER NAME\n",
      "  6: REL\n",
      "  7: GENDER\n",
      "  8: AGE BAND\n",
      "  9: ICD CODE\n",
      "  10: ICD DESCRIPTION\n",
      "  11: ICD VERSION\n",
      "  12: DRUG CLAIMS\n",
      "  13: PAID CLAIMS\n",
      "  14: CLAIMANT TOTAL\n",
      " \n",
      "\n",
      "Select Index # to match: 4\n",
      "--------------------------\n",
      " \n",
      "----IDENTIFYING MATCH COLUMN----\n",
      "  Review header columns for: C:\\Users\\a0766635\\Desktop\\Python\\Cigna Med Rx 1\\data\\CIGNA - Med & Rx2019.xlsx, 18-19-1\n",
      " \n",
      "  0: BRANCH\n",
      "  1: FAT\n",
      "  2: RAT\n",
      "  3: MEMBER ID\n",
      "  4: EMPLOYEE ID\n",
      "  5: SUBSCRIBER NAME\n",
      "  6: REL\n",
      "  7: GENDER\n",
      "  8: AGE BAND\n",
      "  9: ICD CODE\n",
      "  10: ICD DESCRIPTION\n",
      "  11: ICD VERSION\n",
      "  12: DRUG CLAIMS\n",
      "  13: PAID CLAIMS\n",
      "  14: CLAIMANT TOTAL\n",
      " \n",
      "\n",
      "Select Index # to match: 4\n",
      "--------------------------\n",
      "Ready to move on? Yes=1, No=2: 1\n"
     ]
    }
   ],
   "source": [
    "# ##here you identify which column header you will be matching all the files on\n",
    "print(\"Processing: identifying match criteria\")\n",
    "print (\"Processing: This may take a few minutes... \")\n",
    "Combined_df_list = []\n",
    "Match_Type = 'str' \n",
    "Match_ID_ColNum =[]\n",
    "Match_ID = []\n",
    "confirm =2\n",
    "while not confirm ==1:\n",
    "    print(\" \")\n",
    "    for i in range(0, n): \n",
    "        try: \n",
    "            print(\" \")\n",
    "            Matching_Options=list(exceldict[dfname[i]].columns)\n",
    "            print(\"----IDENTIFYING MATCH COLUMN----\")\n",
    "            print(f\"  Review header columns for: {filename[i]}, {sheetname[i]}\")\n",
    "            print(\" \")\n",
    "            for index, cols in enumerate(Matching_Options):\n",
    "                print (f'  {index}: {cols}')\n",
    "            print(\" \")\n",
    "            print(\"\")\n",
    "            match = int(input(\"Select Index # to match: \")) \n",
    "            #dfname[i][\"_Selected Match\"]=dfname[i][[Matching_Options[match].str]]\n",
    "            Match_ID.append(Matching_Options[match]) ## adding the element \n",
    "            Match_ID_ColNum.append(match)\n",
    "            print(\"--------------------------\")\n",
    "    #         print(f'Confirm no quoations: you selected: {Match_ID[i]}')\n",
    "            exceldict[dfname[i]][\"_Match\"]=exceldict[dfname[i]][Matching_Options[match]].astype(dtype= \"str\").replace('\\.0', '', regex=True)\n",
    "            get_unique=exceldict[dfname[i]][\"_Match\"]\n",
    "            for i in get_unique: \n",
    "                if i not in Combined_df_list: \n",
    "                    Combined_df_list.append(i)\n",
    "        except:\n",
    "            print(\"Error - please restart your file\")\n",
    "    confirm = int(input(\"Ready to move on? Yes=1, No=2: \"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  _Match\n",
      "74           00221011701\n",
      "83           00804723201\n",
      "84           01008801901\n",
      "95           01076862001\n",
      "47       044484444723201\n",
      "86           04886663301\n",
      "14         0585433323201\n",
      "4            06166689901\n",
      "103          06999903801\n",
      "75           08990809701\n",
      "104          09070443101\n",
      "87           09097987001\n",
      "101          09310214801\n",
      "82           09322633801\n",
      "81           09414620301\n",
      "96           10800143401\n",
      "89           11072737701\n",
      "27       113335003331201\n",
      "54         1144472737701\n",
      "21   1153332333333333301\n",
      "92           11700071201\n",
      "60         1174440071201\n",
      "93           12404106901\n",
      "61         1244444106901\n",
      "28           12454106901\n",
      "79           12660310101\n",
      "43         1266031444101\n",
      "9            12660315101\n",
      "64       144484440143401\n",
      "31           15850143401\n",
      "29         2169423338501\n",
      "94           21694278001\n",
      "62         2169427844401\n",
      "37         2309393334101\n",
      "69           23093974101\n",
      "20     23163336533333301\n",
      "88           23167607701\n",
      "53         2316764447701\n",
      "7            23639680401\n",
      "39       333664233365501\n",
      "2          3336816351301\n",
      "100          36280400101\n",
      "68       362804444444101\n",
      "36           36280455101\n",
      "90           36808007601\n",
      "57       368444804447601\n",
      "24         3685805333601\n",
      "6          3969320933301\n",
      "78           39693209701\n",
      "85           40231746001\n",
      "80           40799493401\n",
      "98           40874639101\n",
      "18     43333333330419001\n",
      "3            43819930201\n",
      "42         4440221011701\n",
      "48     44410444884441901\n",
      "63       444144476862001\n",
      "49         4444231746001\n",
      "44         4444799493401\n",
      "66         4444874639101\n",
      "50         4444886663301\n",
      "72         4446999903801\n",
      "73       444907444443101\n",
      "52         4449097987001\n",
      "70       444931444214801\n",
      "46         4449322633801\n",
      "45       444941462444301\n",
      "16         4523133346001\n",
      "10         4533399493401\n",
      "33         4583334639101\n",
      "26     46093334033333301\n",
      "59           46097407701\n",
      "32         4633394305201\n",
      "23         4649391633301\n",
      "56           46493916701\n",
      "97           46794300201\n",
      "65         4679430444201\n",
      "41           46984186801\n",
      "51           47770419001\n",
      "0          5022101133301\n",
      "15           51058851901\n",
      "30         5153336862001\n",
      "17           54886663301\n",
      "40           56999903801\n",
      "19       590933398333001\n",
      "38           59315214801\n",
      "13           59322633801\n",
      "12           59414625301\n",
      "35         6241233352401\n",
      "99           62412702401\n",
      "67         6241274442401\n",
      "34           63286218401\n",
      "25       633304423335001\n",
      "22         6393338028301\n",
      "55           63978028301\n",
      "77           64202686901\n",
      "5            64252686901\n",
      "91           67044270001\n",
      "58         6704427444001\n",
      "102          76642760001\n",
      "71       766427644444401\n",
      "76           76816301301\n",
      "11           82232046301\n"
     ]
    }
   ],
   "source": [
    "#Combined_vlookup_table['_Match'].apply(lambda x: '%.0f' % x).values.tolist()\n",
    "#pd.options.display.float_format = '{:.2f}'.format\n",
    "Combined_vlookup_table = pd.DataFrame(Combined_df_list)\n",
    "Combined_vlookup_table.rename(columns={0:'_Match'}, inplace=True )\n",
    "Combined_vlookup_table.dropna(how='any', inplace=True)\n",
    "Combined_vlookup_table['_Match'].replace(\" \", np.nan, inplace=True)\n",
    "Combined_vlookup_table['_Match'].replace(\"nan\", np.nan, inplace=True)\n",
    "Combined_vlookup_table.dropna(inplace=True)\n",
    "Combined_vlookup_table.sort_values(\"_Match\", inplace = True)\n",
    "#pd.set_option('display.max_rows', Combined_vlookup_table.shape[0]+1)\n",
    "#print(Combined_vlookup_table)\n",
    "#Combined_vlookup_table.dtypes\n",
    "#print(\"Processing: successful match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the combined df's and ask if any lines need to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: creating unique claimant #s \n"
     ]
    }
   ],
   "source": [
    "print(\"Processing: creating unique claimant #s \")\n",
    "# ##Creates new column \"UniqueClaimant\" \n",
    "ClaimantID = [f'Claimant {i}' for i in range(1,1+len(Combined_vlookup_table))]\n",
    "\n",
    "# ##this adds ClaimantID to the combined dataframe and names if Unique Claimant\n",
    "Combined_vlookup_table[\"UniqueClaimant\"] = ClaimantID\n",
    "Combined_vlookup_table.columns.name=None\n",
    "#Combined_vlookup_table\n",
    "#print(\"Processing: unique claimant #s created\")\n",
    "\n",
    "# Combined_vlookup_table.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vlookup tables in each file and outside file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: creating vlookup sheets in folder\n",
      "Processing: vlookup sheet in folder created\n",
      "Are your xlsx files closed? 1=Yes, 2=No: 1\n",
      "Processing: creating vlookup sheet in exisiting excel\n",
      "Processing: 17-18-1\n",
      "Processing: 18-19-1\n",
      "Processing: 18-19-1\n",
      "\n",
      "Processing: vlookup sheet in exisiting excel created\n"
     ]
    }
   ],
   "source": [
    "os.chdir = file_path\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ##creates date to add to end of file\n",
    "# today = date.today()\n",
    "\n",
    "# ##exports vlookup table into same folder as the file and creates two tabs, 1 for just unique claimant and other with all columns\n",
    "# Combined_vlookup_table.to_excel (f'_Automated_Lookup{today}.xlsx', sheet_name='Automated_Lookup', index = False, header=True,)\n",
    "# #Combined_df.to_excel (f'_Automated_Full Report{today}.xlsx', sheet_name='Automated_all_col', index = False, header=True,)\n",
    "\n",
    "# print('Processing: vlookup sheet in folder created')\n",
    "# close_file = 2\n",
    "# while not close_file == 1:\n",
    "#     close_file = int(input(\"Are your xlsx files closed? 1=Yes, 2=No: \"))\n",
    "#     if close_file == 1:\n",
    "#         print('Processing: creating vlookup sheet in exisiting excel')\n",
    "#         ##exports vlookup table into original file\n",
    "#         for i in range(len(exceldict)):\n",
    "#             path = filename[i]\n",
    "#             with pd.ExcelWriter(path, engine='openpyxl') as writer:\n",
    "#                 wb = openpyxl.load_workbook(filename = path)\n",
    "#                     wb = openpyxl.load_workbook(filename = filename[i])\n",
    "#     sheet = wb[sheetname[i]]\n",
    "# #                 writer.wb = book\n",
    "# #                 writer.sheets = dict((ws.title,ws) for ws in book.worksheets)\n",
    "#                 sheet = wb[sheetname[i]]\n",
    "#                 #sheet.cell(row= headerrow[i]+1, column=len(exceldict[key].columns)+1).fill = PatternFill(start_color=\"98ea64\", end_color=\"98ea64\", fill_type = \"solid\")\n",
    "#                 Combined_vlookup_table.to_excel(path, sheet_name= f'Automated_Lookup', header=True, index=False)\n",
    "#                 sheet=book[\"Automated_Lookup\"]\n",
    "#                 sheet.sheet_properties.tabColor = 'FF0000'\n",
    "#                 book.save(filename[i])\n",
    "#                 writer.save()\n",
    "#     else:\n",
    "#         pass\n",
    "# print(\"\")\n",
    "# print('Processing: vlookup sheet in exisiting excel created')\n",
    "print (\"Processing: creating vlookup sheets in folder\")\n",
    "\n",
    "##creates date to add to end of file\n",
    "today = date.today()\n",
    "\n",
    "##exports vlookup table into same folder as the file and creates two tabs, 1 for just unique claimant and other with all columns\n",
    "lookup = '/Automated_Lookup{0}.xlsx'.format(today)\n",
    "Combined_vlookup_table.to_excel (file_path + lookup, sheet_name='Automated_Lookup', index = False, header=True,)\n",
    "#Combined_df.to_excel (f'_Automated_Full Report{today}.xlsx', sheet_name='Automated_all_col', index = False, header=True,)\n",
    "\n",
    "print('Processing: vlookup sheet in folder created')\n",
    "close_file = 2\n",
    "while not close_file == 1:\n",
    "    close_file = int(input(\"Are your xlsx files closed? 1=Yes, 2=No: \"))\n",
    "    if close_file == 1:\n",
    "        print('Processing: creating vlookup sheet in exisiting excel')\n",
    "        ##exports vlookup table into original file\n",
    "        for i in range(len(exceldict)):\n",
    "            print(f\"Processing: {sheetname[i]}\")\n",
    "            book = load_workbook(filename[i])\n",
    "            writer = pd.ExcelWriter(filename[i], engine='openpyxl')\n",
    "            writer.book = book\n",
    "            writer.sheets = dict((ws.title,ws) for ws in book.worksheets)\n",
    "#                 sheet = writer.book[sheetname[i]]\n",
    "                #sheet.cell(row= headerrow[i]+1, column=len(exceldict[key].columns)+1).fill = PatternFill(start_color=\"98ea64\", end_color=\"98ea64\", fill_type = \"solid\")\n",
    "            Combined_vlookup_table.to_excel(writer, sheet_name= f'Automated_Lookup', header=True, index=False)\n",
    "            sheet=book[\"Automated_Lookup\"]\n",
    "            sheet.sheet_properties.tabColor = 'FF0000'\n",
    "#                 book.save(filename[i])\n",
    "            writer.save()\n",
    "    else:\n",
    "        pass\n",
    "print(\"\")\n",
    "print('Processing: vlookup sheet in exisiting excel created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.excel._openpyxl._OpenpyxlWriter at 0x383a601c8>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\a0766635\\\\Desktop\\\\Python\\\\TESTING ROOM\\\\data\\\\Test - Med & Rx2017.xlsx'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Add Vlookup formula to the excel\n",
    "- Need to make the column that you are referencing auto turn to \"text\" and not \"general\"\n",
    "- need to figure out how to get coordinates to the columns and row for referencing and writing vlookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----MATCHING COLUMNS IN EXCEL----\n",
      "Analyzing file: C:\\Users\\a0766635\\Desktop\\Python\\Cigna Med Rx 1\\data\\CIGNA - Med & Rx2017onDesk.xlsx :: sheet 17-18-1 dimensions A5:AF101\n",
      " Processing: begin row E12, end row E101\n",
      " \n",
      "-------\n",
      "----MATCHING COLUMNS IN EXCEL----\n",
      "Analyzing file: C:\\Users\\a0766635\\Desktop\\Python\\Cigna Med Rx 1\\data\\CIGNA - Med & Rx2018.xlsx :: sheet 18-19-1 dimensions A5:R94\n",
      " Processing: begin row E12, end row E94\n",
      " \n",
      "-------\n",
      "----MATCHING COLUMNS IN EXCEL----\n",
      "Analyzing file: C:\\Users\\a0766635\\Desktop\\Python\\Cigna Med Rx 1\\data\\CIGNA - Med & Rx2019.xlsx :: sheet 18-19-1 dimensions A5:Q109\n",
      " Processing: begin row E12, end row E109\n",
      " \n",
      "-------\n",
      "\n",
      "\n",
      "Finished. Please check your file for vlookup tab and formulas in main sheets\n",
      "Code run time: 00:02:10.90\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(exceldict)):\n",
    "    wb = openpyxl.load_workbook(filename = filename[i])\n",
    "    sheet = wb[sheetname[i]]\n",
    "\n",
    "    print(\"----MATCHING COLUMNS IN EXCEL----\")\n",
    "    print (f'Analyzing file: {filename[i]} :: sheet {sheetname[i]} dimensions {sheet.dimensions}')\n",
    "    row_max_count = sheet.max_row\n",
    "    row_min_count = sheet.min_row\n",
    "    column_max_count = sheet.max_column\n",
    "    column_min_count = sheet.min_column\n",
    "    col_min = colnum_string(column_min_count)\n",
    "    col_max = colnum_string(column_max_count+1)\n",
    "    col_match_letter = colnum_string(Match_ID_ColNum[i]+1)\n",
    "    startrow = headerrow[i]+1\n",
    "\n",
    "\n",
    "    print(f' Processing: begin row {col_match_letter}{startrow}, end row {col_match_letter}{row_max_count}')\n",
    "    print(\" \")\n",
    "    for row in sheet[f'{col_max}{startrow+1}:{col_max}{row_max_count}']:\n",
    "        for cell in row:\n",
    "            lookup_value=sheet[f'{col_match_letter}{cell.row}'].value\n",
    "            # check if lookup_value is blank\n",
    "            if lookup_value:\n",
    "                if is_numeric_dtype(exceldict[dfname[i]][Match_ID[i]])== True:\n",
    "                    cell.value = \"=VLOOKUP({0}, 'Automated_Lookup'!A:B, 2, FALSE)\".format('\"'+str(lookup_value).lstrip('0')+'\"')\n",
    "                else:\n",
    "                    cell.value = \"=VLOOKUP({0}, 'Automated_Lookup'!A:B, 2, FALSE)\".format('\"'+str(lookup_value)+'\"')\n",
    "                    \n",
    "    for row in sheet[f'{col_max}{startrow}:{col_max}{startrow}']:\n",
    "        for cell in row:\n",
    "            lookup_value=sheet[f'{col_match_letter}{cell.row}'].value\n",
    "            # check if lookup_value is blank\n",
    "            if lookup_value:\n",
    "                cell.value = \"Unique Claimant ID\"\n",
    "                sheet.cell(row= startrow, column=column_max_count+1).fill = PatternFill(start_color=\"98ea64\", end_color=\"98ea64\", fill_type = \"solid\")\n",
    "\n",
    "                \n",
    "            \n",
    "#             cell.value = \"=VLOOKUP(TEXT(VALUE({0}{1}),0), 'Automated_Lookup'!A:B, 2, FALSE)\".format(col_match_letter, cell.row)\n",
    "            #cell.value = \"=IF(VLOOKUP({0}{1}, 'Automated_Lookup'!A:B, 2)=\"\", \"\",VLOOKUP({0}{1}, 'Automated_Lookup'!A:B, 2))\".format(col_match_letter, cell.row)\n",
    "    \n",
    "        #sheet.cell(row= row_min_count, column= column_max_count.fill = PatternFill(start_color=\"98ea64\", end_color=\"98ea64\", fill_type = \"solid\")\n",
    "\n",
    "               \n",
    "#     print(f' Processing: begin row {col_match_letter}{startrow}, end row {col_match_letter}{row_max_count}')\n",
    "#     print(\" \")\n",
    "#     for row in sheet[f'{col_max}{startrow+1}:{col_max}{row_max_count}']:\n",
    "#         for cell in row:\n",
    "#             lookup_value=sheet[f'{col_match_letter}{cell.row}'].value\n",
    "#             # check if lookup_value is blank\n",
    "#             if lookup_value:\n",
    "#                 #cell.value = \"=VLOOKUP({0}, 'Automated_Lookup'!A:B, 2, FALSE)\".format('\"'+str(lookup_value).lstrip('0')+'\"')\n",
    "#                 cell.value = \"=VLOOKUP({0}, 'Automated_Lookup'!A:B, 2, FALSE)\".format('\"'+str(lookup_value)+'\"')\n",
    "# #             cell.value = \"=VLOOKUP(TEXT(VALUE({0}{1}),0), 'Automated_Lookup'!A:B, 2, FALSE)\".format(col_match_letter, cell.row)\n",
    "#             #cell.value = \"=IF(VLOOKUP({0}{1}, 'Automated_Lookup'!A:B, 2)=\"\", \"\",VLOOKUP({0}{1}, 'Automated_Lookup'!A:B, 2))\".format(col_match_letter, cell.row)\n",
    "#             #         sheet.cell(row= headerrow[i]+1, column=1+len(exceldict[key].columns)).fill = PatternFill(start_color=\"98ea64\", end_color=\"98ea64\", fill_type = \"solid\")\n",
    "\n",
    "    \n",
    "    wb.save(filename[i])\n",
    "\n",
    "    print(\"-------\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print (\"Finished. Please check your file for vlookup tab and formulas in main sheets\")\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"Code run time: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "os.system(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
